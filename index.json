[{"categories":[],"contents":"Summary I\u0026rsquo;ve made a Tableau Public profile to showcase any public datasets I\u0026rsquo;ve analysed in Tableau:\nLink to Tableau Public: https://public.tableau.com/app/profile/filip.livancic\n","permalink":"https://filpill.github.io/data_projects/tableau_public/","tags":[],"title":"Tableau Public Profile - Filip Livancic"},{"categories":["programming"],"contents":"Summary I\u0026rsquo;ve been very involved in practising my programming skills in python and sql lately on codewars.\nI figured it would be a good idea to visualise my codewars progression.\nI\u0026rsquo;m utilising the codewars public API to pull out my information. The user data is processed in Python with the output being consolidated into a Excel dashboard using Xlsxwriter.\nLink to project: https://github.com/Filpill/codewars-stats\nAnalytics Process Flow graph TD; subgraph Process Initiation 0([Python Notebook Executed])--\u003eA[HTTPS Request Codewars Username Stats] end subgraph Return JSON A--\u003eC[Username Profile Data] A--\u003eD[List of Compeleted Kata by User] A--\u003eE[Individual Challenge Details] end subgraph Merge Data D--\u003eF[Merge Data via the Kata ID] E--\u003eF F--\u003eG[Re-name Columns to Better Format] end subgraph Count Aggregates G--\u003eH[Categories] G--\u003eI[Monthly Completions] G--\u003eJ[Kata Rank] G--\u003eK[Languages] end subgraph Visualisation H--\u003eL[Graphing Cats.] I--\u003eM[Graphing Comp.] J--\u003eN[Graphing Rank.] K--\u003eO[Graphing Lang.] end subgraph XlsxDashboard L--\u003eP[Insert and Format Tabular Data] M--\u003eP N--\u003eP O--\u003eP P--\u003eQ[Insert Matplotlib Charts] Q--\u003eR([Close Xlsxwriter Workbook Object]) end Data Visualisations ","permalink":"https://filpill.github.io/data_projects/codewars/","tags":["python","sql"],"title":"Codewars API - User Statistics"},{"categories":["data","programming"],"contents":"Summary I\u0026rsquo;ve been in the process of developing numerous Tableau dashboards across different areas of the airline business to share safety data across the organisation.\nHowever, there is no easy way to download all the various charts from dashboard views you have produced to recycle for the purpose of a powerpoint presentation.\nIdeally we want to avoid duplicating the data analytics process in other systems such as Python as we don\u0026rsquo;t want to incur uncessary work to present the same information.\nThe Tableau Client Server API helps solve this issue by enabling us to programatically extract dashboard images in an effcient manner.\nProcess Overview iPython/Jupyter Notebook Connecting to the Tableau Client Server API with personal access token. Collating all Projects and Views into table and utilising view id\u0026rsquo;s to extract dashboard images in conjunction with Pandas. Dashboard images cropped down to chart dimensions with a Python Image Library prepare image for presentation use. Link to the project here: Tableau Dashboard Image Extraction Notebook\nTableau Client Server API Workflow graph TD; subgraph Process Initiation 0([Python Notebook Executed])--\u003eA[Personal Access Tokens: Authenticating Valid API Connection\nwith Tableau Server] end subgraph Get Requests: Server Object ID's A--\u003eC[Gathering Project ID's] A--\u003eD[Gathering Workbook ID's] A--\u003eE[Gathering View ID's] end subgraph Combine \u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp; Data C--\u003eF[Merging ID Info into Single Pandas DataFrame] D--\u003eF E--\u003eF F--\u003eG[Filtering DataFrame to Selected Project ID] G--\u003eH[Collecting List of Server View Objects] end subgraph Process \u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;Images H--\u003eI[Saving all the Images of View Objects] I--\u003eJ[Python Image Library\nCrop Images to Correct Dimensions] J--\u003eK([Save Cropped Dashboard Images]) end Conclusion As you can see, the process for extracting the Tableau image data from dashboards is fairly straightforward.\nWith the View ID, you are able to extract the full dashboard image. The only drawback is that there is no way to pull out the individual charts from the dashboard view via this API. Therefore you need to specify all the pixel dimensions to crop the images into their respective charts.\nThe only alternative is to implement a web-scraping technique on Tableau Server and figure out a way to pull down the chart data. It would probably require something like Selenium because of the dynamic nature of the website.\nRegardless, with the Tableau Client Server API you will still benefit from the dashboard image extraction in addition to allowing you to repurpose your existing dashboards for presentation purposes.\n","permalink":"https://filpill.github.io/data_projects/tableauapi/","tags":["python","tableau","automation","programming"],"title":"Tableau Client Server API: Extracting Dashboard Images"},{"categories":["data"],"contents":"Summary I\u0026rsquo;ve played a decent number of chess games on the chess.com platform since 2019 and all my chess data can be explored using the API endpoints documented inside the website.\nI was interested in monitoring how my rating has changed over the cumalative number of games played.\nI was playing chess casually so my improvement was marginal compared to the upper echelon of chess skill. Additionally, I wasn\u0026rsquo;t learning chess strategy or tactics in depth.\nThough it was still fun to visualise the progression graphically.\nLink to the project here: Chess.com - Jupyter Analysis\nData Visualisations ","permalink":"https://filpill.github.io/data_projects/chess/","tags":["python","data","programming","webscraping"],"title":"Chess.com API - Data Visualisation"},{"categories":["data","programming"],"contents":"Summary There are endless oppertunities to streamline processes and automate our data production tasks.\nThis article serves as an example for the wide ranging applications I\u0026rsquo;ve been using Python to automate both simple and complex tasks with high efficiency.\nData Modelling These are some of the goals we are trying to achieve:\nTo build complete end-to-end data solutions from the data source to user. We want to minimise manual task interventions during the data processing. To build tools which are adaptable to the needs of the business. This is a high level view of a data analytics pipeline I\u0026rsquo;ve built in the past: graph TD; subgraph Process Initiation 0A([Data Analyst Initiates Process])--\u003eA 0A--\u003eB end subgraph Extract, Transform, and Analyse Data A[Shell Scripts]-- exec. via cli tools --\u003eC((Python Scripts)) B[Task Scheduler]-- auto exec. --\u003eC((Python Scripts)) D[(SQL Server)]-- data retrieval --\u003eC-- pyodbc --\u003eD C--\u003e E(Matplotlib charts) C--\u003e F(Pandas tables) E-- saved as .png --\u003e G(Saved In Network Drive) F-- saved as .csv --\u003eG subgraph Create Data Product G-- xlsxwriter --\u003eH(Excel\nDashboards) G-- python-pptx --\u003eI(Powerpoint\nPresentations) end end subgraph Process Termination H--\u003eJ(Emails sent via SMTP) I--\u003eJ J-- smtplib --\u003eK([End User Recieves Data Product]) end Note: Python scripts are chained together to connect the processes together and handle various tasks along the pipeline\nThis is the result of incremental upgrades made gradually over time to optimise my workflow. I\u0026rsquo;ve saved much time inter-weaving these python libraries together.\nAs long as the tools are well built, you can bridge them across to new processes easily and maintain them with minimal effort. Not to mention you will be saving hundreds (and maybe thousands of) hours as you execute these processes.\nThe idea is not to replicate this system one-to-one, but to demonstate the possibilities for connecting automation tools togther.\nAnd perhaps we can learn to make more elaborate systems\u0026hellip;\nPyODBC - A SQL Interface For Python The most important setup of the automation process is the ingestion of data into the Python environment.\nFortunately for myself, our organisation hosts several Microsoft SQL Servers which form part of our data warehouse.\nPyODBC is a python module which can authenticate and connect directly to your desired SQL server. The great thing about it is that you can wrap an entire query written in SQL with a triple quote string directly within your python script. The module will be able to send the query out using the relevant ODBC driver on your machine.\nThe pyodbc set-up can be generalised because you only need two inputs: the server name and the sql query. Therefore I have developed a python utility written which can be imported into any data processing script as a module.\nXlsxWriter - Excel Report Generator For Python The proliferation of Excel as a standard piece of software has enabled much easier sharing and communication of data. There is no office computer in the world that is not supplied with Excel.\nBI tools are also used to communicate and share data accross the business. However, this depends on how much the organisation can stretch the budget to license the majority of individuals.\nWorking inside the Excel ecosystem can help save on the extra overhead. However, we don\u0026rsquo;t want to be doing any analysis in Excel.\nWhy?\u0026hellip;\nBecause it\u0026rsquo;s extremely computationally expensive to handle large data sets. And its next to useless when stringing together a series of complex formulas to analyse data.\nHow can we solve this issue? Simple \u0026ndash; Xlsxwriter.\nXlsxwriter is a python module which allows you to create fresh Excel reports from scratch with analysis conducted in Python. You can turn all your pandas dataframes into Excel tables. Additionally, matplotlib charts can be inserted into the workbook to act as the visualisation component.\nWith a bit of effort, you can easily turn the analysis into a dashboard that mimics the appearance of an Excel spreadsheet. I frequently use this tool to get dashboards into production quickly with python.\nNote: XlsxWriter as the name suggests \u0026ldquo;writes Excel Workbooks\u0026rdquo;. To be clear, this is not an API that can directly interact with objects of pre-existing workbooks. Everytime you execute a script with xlsxwriter tools involved, a completely new file will be produced and overwrite the previous version.\nPython-Pptx - PowerPoint Presentation Generator For Python How many hours do you waste making powerpoints? I\u0026rsquo;ve spent countless hours adjusting trivial features such as formatting or chart positioning.\nBut what if the presentation content and design can be prepared automatically?\nI generate tens of presentations per month to cater to multiple stakeholders. Given that I have fairly standardised slide content, this makes presentations a high value automation target for myself.\nI\u0026rsquo;ve experimented with markdown presentation tools. However, I run into a lot of issues where I do not have full positional control of the objects.\nStakeholders tend to ask for extra features or to move shapes around the slide. However, this is happens to be the power of python-pptx library.\nPython-pptx is much more powerful in controling the powerpoint design in comparison to letting markdown dictate all the default positions of your powerpoint shapes.\nThe control of the objects is very granular its therefore very important to set up functions to standardise some layouts or shapes you want to insert. This speeds up the presentation building process as usually slides tend to borrow a lot of the same code.\nThe powerpoint functions I write are imported from a seperate .py file. A global function file helps us share the functions to any python script involving presentation automation.\nNote: Python-pptx works in similar fashion to xlsxwriter. Everytime the script is run, a brand new presentation file will be built from sratch.\nSmtplib - Email Automation with Python Routine emails sent on a recurring basis can be automated using the python library smtplib.\nWe can borrow the SMTP protocol to send our emails and we can avoid our GUI email environment entirely. Python acts as the interface and can send the email directly.\nThe script can be designed to have a message template built into itself. Additonally, we can make a list of tuples containing the addresses and attachments you want to send to the respective parties.\nBy looping over these templates and lists, we can entirely bypass the requirement of building all the components for all the emails.\nTens of emails can be sent out in a matter of seconds.\nConclusion Considering the tasks we do daily,weekly and monthly; we can tie our procedures together with an elaborate series of Python tools to save hundreds, if not thousands of hours.\nFor most organisations, the cost benefit ratio is extremely favourable if automation systems are applied (and maintained) correctly.\nThe value of your time increases exponentially as you are able to prioritise resources in creating higher quality work.\n","permalink":"https://filpill.github.io/data_projects/data_system/","tags":["python","sql","powerpoint","outlook","excel","automation","programming"],"title":"Building Data Pipelines With Python: Systems Perspective"},{"categories":["programming"],"contents":"Summary Documenting the most common ways I interact with git and in maintaining my programs. For reference these actions are performed via the command line.\nIn my opinion the main benefit of using a CLI is the added efficiency of the scripting out the majority of the process via usage of shell scripts.\nThis allows you to direct all of your attention on effortless creating work without getting lost in a GUI just to push a new commit.\nConnections and Authentication There are 2 main ways to connect to a git repository. We can either use the HTTPS or SSH protocols respectively.\nSSH has the advantage of having passwordless interactions with git which I strongly recommended when pushing code. Its very easy to set-up an SSH key-pair; it saves time and its very secure. (Assuming you take the right precautions to protect your ssh-keys!)\nI would only use HTTPS if I am cloning someone-elses public repository but not for maintaining my personal repos'.\nI won\u0026rsquo;t discuss the methods of generating access tokens which can be used to authenticate an https connection. In my experience this is the inferior way to authenticate your connection unless you have some sort of specific reasons to use https with an access token.\nCreate Local Repo and Connect to Remote Repository Go to Github and create a new repository Go to the working directory of your machine and initialise the local repo by typing: git init Connect local repo to remote repo by typing: git remote set-url origin repo_ssh_address Cloning a Github Repo Go to Github and copy ssh address of repository Go to the directory where you want to clone the repository into and type: git clone repo_ssh_address Or if you don\u0026rsquo;t have an ssh key-pair set-up ,you can just switch the address with the HTTPS version which works just the same: git clone repo_https_address Creating SSH Keys for Authentication Protocol Go to your dot ssh directory which is storing ssh-keys Type this command to generate an SSH Keypair: ssh-keygen -t rsa -b 4096 -C youremail@yourdomain.com Name your SSH keys, and skip password prompts Copy the public key of the two that were generated and paste into the Github settings where you are saving your public keys Initialise SSH-Agent and Add Private SSH Key To Key Chain This only lasts as long as your terminal instance is open. If you close the terminal, you need to re-type the commands to restart the ssh-agent for the next terminal you spawn.\nNote: The ssh agent process only linked to the terminal you typed it in. So you will need to initialise the ssh-agent for every terminal instance you spawn (if you working on multiple terminals).\nI\u0026rsquo;ve already saved this as an shell script to save the effort of writing these commands all the time.\nTo start ssh-agent type: eval `ssh-agent` To add the private key to the ssh agent type: ssh-add path/to/your/private/ssh/key Commit Changes to Github Repository Pull the most recent version from the repo by typing: git pull origin main Make ammendments to your work and save it locally To queue up ALL changes to upload, type: git add . To commit the changes type: git commit -m ”add some comments here” \u0026ldquo;To push the committed changes onto the main branch type:\ngit push origin main ","permalink":"https://filpill.github.io/data_projects/github/","tags":["cli","shell","programming"],"title":"Github - Command Line Interface Procedures"},{"categories":["data"],"contents":"Summary I was searching for a Valorant API to collect and analyse some of my own match data. However the developers are not providing personal API keys for this particular game.\nThere are some websites which are publishing the Valorant data into the public domain. I decided to scrape my own match data which is being hosted on their web clients.\nThough the volume of data highlighted on the website is limited compared to the actual volume of games I\u0026rsquo;ve played. I was only able to pull 30 matches worth of data.\nHowever, it was worth learning about the overall web-scraping process and adding more capabilities to my toolkit.\nLink to the project here: Valorant Web Scrapping Project\nScrapy - Web Scraper I used a python library called scrapy as my web-crawling tool and the website being interrogated was https://dak.gg/valorant/en/profile/FilPill-EUW\nInitialising Scrapy Project The command below creates all the starting files for building the web-crawler:\nscrapy startproject val_scraper Checking for 200 Response on Target Website I initialised a scrapy shell with the command:\nscrapy shell Inside the shell, I make a request to the website to check that my scraper has permissions to scrape the website.\nfetch (\u0026#39;https://dak.gg/valorant/en/profile/FilPill-EUW](https://dak.gg/valorant/en/profile/FilPill-EUW)a\u0026#39;) A successful connection will return a 200 response, otherwise any 4xx reponse code will inidicate an error or a lack of permissions to perform this specific operation.\nIdentifying Target For Scraping My initial approach involved attempting to parse out the HTML classes within the div\u0026rsquo;s however it did not work successfully. Despite the data being kept inside the HTML tags,I could not access them with my scraper.\nWhen I simulated the webscraper opening the website, it did not return any data at all. Just an empty HTML page with no data. Soonafter, I realised that javascript is being employed to dynamically load the data into the front-end.\nRealising this occurrence, I changed my approach. On the inspect elements page, I naviagted to the XHR/Fetch network tab to view what kind of requests were being made to the website, I found an https request which returns my match data in JSON format.\nThe spider script shown below is what is being ustilised to scrape the match data from the page:\nimport scrapy import json class PlayerState(scrapy.Spider): name = \u0026#39;playerState\u0026#39; start_urls = [\u0026#39;https://dak.gg/valorant/en/profile/FilPill-EUW\u0026#39;] headers = { \u0026#34;accept\u0026#34;:\u0026#34; application/json, text/plain, */*\u0026#34; } def parse(self, response): url = \u0026#39;https://val.dakgg.io/api/v1/accounts/JPnyLxsiavseiYbL8xtmWSuFRHdupX43u_hVynD5YScr2_Y32Wt2v5K-NvxvfDRWTL67AHdVSmoLTg/matches\u0026#39; request = scrapy.Request(url, callback = self.parse_api, headers=self.headers) yield request def parse_api(self,response): raw_data = response.body data = json.loads(raw_data) yield { \u0026#39;matches\u0026#39;:data[\u0026#39;matches\u0026#39;] } Running the spider To run the spider you run the following command:\nscrapy crawl playerState -O playerState.json The playerState argument in the command is referring to the class defined in my spider.\nThe results are saved in a json file of my choosing.\nData Analysis Since we are only pulling out 30 matches, we are fairly limited in generating valuable data visualisations.\nHowever the goal was mainly to gain an understanding of the overall webscraping process.\nThese are some of the visualisations made using python:\n","permalink":"https://filpill.github.io/data_projects/val_scrp/","tags":["scrapy","json","webscraping","programming"],"title":"Valorant API - Web Scraping Project"},{"categories":["design"],"contents":"Summary I wanted to showcase my projects without devoting a large amount of time to maintaining HTML code and needed a framework to make it easy to share my projects.\nHugo is a static site generator written in Go and compiles your documents written in markdown into cleanly formatted HTML and CSS files.\nThe first iteration of my website was manually written in HTML/CSS. It was a little bit ugly compared to the second iteration which is using hugo framework. Additionally, using someone else\u0026rsquo;s theme takes alot of the legwork out of the page design.\nThe compiled HTML files are hosted on my github pages for reference.\nLink to the Hugo Markdown Files\nLink to Static HTML Hotsted on Github Pages\nProcess Here is some general guidance as to how this website was developed from a Linux OS perspective. The guidance should be adapted according to the OS being used:\nGithub Repositories To build and deploy the website, we require two seperate repositories:\nA production repo blog-web: with markup documents and web config. A deployment repo Filpill.github.io: with compiled static HTML files. Content is added to the markdown documents in the production repo. This is later compiled into static HTML.\nThe static files reside in the public folder. They are eventually pushed into the deployment repo.\nThe deployment repository exists so we can allow github to display the HTML files.\nInstalling Hugo I\u0026rsquo;m working from an Arch based Linux OS at the time of development. Installing the hugo on arch can be done with the following pacman command: sudo pacman -S hugo Creating New Website Initialise Website Folders To initialise a new website type the following command into your shell: hugo new site name_of_your_website This will create all the folder templates you need to get started. Website Theme There are a couple of approaches to this, you can either design your own theme or you can choose one that is publicly shared. I chose to use a repository containing a theme called PaperMod which is a minimalistic theme which fits my requirements. cd into your themes directory and clone the repository at that location. I\u0026rsquo;m choosing to use the SSH method to clone into it, however you can also use HTTPS method if you prefer: git clone git@github.com:adityatelange/hugo-PaperMod.git Configuration File The configuration document is in the root directory and is called config.toml This file configures various aspects of your website. How to make a webpage Hugo\u0026rsquo;s webpages reside in the content folder of your website.\ncd to the root of your website To make a new page type: (replace the page_folder and page_name with names of your choice) hugo new page_folder/page_name.md The name of the page and directory automatically form links for your website A new markdown file with a default template will appear for your page. Using markdown, you can populate the file with your webpage content. Images Images are stored in one of two directories. Either the static or assets folder:\nThe static folder exists if you wish to directly use your image in their original state via markdown. You may wish to optimise the image by scaling down the resolution or compressing the image, and this will only be the case if you call the image in the assets folder. You can make some HTML shortcodes to standardise the optimisation you want to apply to the image. Technically .gif files are not optimal inclusions into minimal websites due to the large file size. Although I like the visual presentation they provide. Compiling on Local Server Observing the compiled version of the (draft) website is simple, type the following command:\nhugo server -D Adding the -D argument at the end also compiles the documents with the draft status set to true. Omitting the -D at the end of the command will not render documents in draft state. The local website host is at this address: http://localhost:1313/ Adding a Submodule A git submodule is a record within that points to a specific commit in another directory.\nThis is a key component of this workflow as we want to send the contents of our public folder and point it to an external repo where we are hosting.\nIn our case want our deployment repo Filpill.github.io to be a submodule of the projects repo.\nTherefore we want to cd into the root folder of our projects website (blog-web) and type:\ngit submodule add -b main git@github.com:Filpill/Filpill.github.io.git public And this enables us build from blog-web and to push code from the public folder of blog-web straight to Filpill.github.io\nCompiling Static Files into Public Folder In order to compile the files nessesary for the deployment repository on git. Type the following command in the root directory of website:\nhugo -t hugo-PaperMod -D The argument after \u0026ldquo;-t\u0026rdquo; is theme which is being used to compile the website together. In my case I\u0026rsquo;m using hugo-PaperMod. The resulting files will compile straight into the public folder. Again similarly to the local host, adding a \u0026ldquo;-D\u0026rdquo; will transform draft pages as well as the finalised pages. You can choose to omit the \u0026ldquo;-D\u0026rdquo; when you are finalising the website. But you must change the draft state in the markdown pages. Deploying pages onto your Github Since all the static files are compiled in public and we have that folder pointing towards the deployment repo. We can just write our git commands to push the changes into deployment.\ncd public/ git add . git commit -m \u0026#34;deploying compiled html\u0026#34; git push origin main At this stage we have website up and running and hosted on github. Adding new content to the website is easily achieved with new markdown files. And changes are pushed with the previous 2 steps. Or we could script this out completely with a shell script.\n","permalink":"https://filpill.github.io/data_projects/hugo/","tags":["html","css","markdown","go","website","javascript","shell","vim","scripting"],"title":"Website Design with Hugo Framework"},{"categories":null,"contents":"About Me Aeronautical engineering educational background: Aero/Mechanical + Aircraft Design Self-taught data analytics programmer: Python/Microsoft SQL Server Highly knowledgeable in airline safety management domain Interested in automation of data analytics Hobbyist 3D Print Designer Hobbyist Glider Pilot Links Resume Profile Filip\u0026rsquo;s Data Projects Website Codewars Profile ","permalink":"https://filpill.github.io/profile/","tags":["html","css","hugo","web"],"title":"Profile"},{"categories":["data"],"contents":"Summary I decided to showcase some data transformations on I game that usually play and see if I could get some cool visualisations/insights. I\u0026rsquo;m using an API to replicate a sample of data visualisations I would typically make. In my work I normally query out of a SQL database for my data ingestion but trying something new here as an experiment. This was my first time using an API to extract JSON data, but its very easy to manipulate on Python to transform into a dict/dataframe. Link to Age of Empires 2 Data Project\nData Visualisations ","permalink":"https://filpill.github.io/data_projects/aoe2/","tags":["programming","python","api","data","visualisation","dashboard","analytics"],"title":"Age of Empire 2 API - Data Visualisation"},{"categories":["engineering","design"],"contents":"Summary Designed a 3D printed lithophane lamp in Soldworks. Main feature: Replaceable lithophanes of chosen standard of aspect ratio/dimension. Features Top/Bottom Panels retained with three M3 screws \u0026ndash; Removing the panels gives access to replacing the printed lithophane. Wiring threads through back of assembly and socket leans on back the back panel. Forward attachment clamps the socket and constrains the foward movement of the light socket with screws. I have two slightly different designs to accomadate either an E14 lamp socket or an E27 lamp socket. This was due to supply issues of light sockets at the time of design which prompted a redesign due to time constraints. Printing and Design Images are preprocessed to correct specs and lithophane stl\u0026rsquo;s are generated using: https://itslitho.com\u0026quot; Lithophane thickness paramaters: smallest wall thickness 0.9mm largest wall thickness is 3mm border thickness: 5.25mm Printed on Creality Ender 3 pro: 0.4mm nozzle Total print time is 26 hours (my printer set-up) Animation The version shown below in the pictures is the E14 litho lamp: Max Width = 185mm Height = 130mm ","permalink":"https://filpill.github.io/eng_projects/litho/","tags":["lithophane","3d-printing","design","engineering","photoshop"],"title":"Lithophane Lamp"},{"categories":["engineering","design"],"contents":"Summary Personal project to design and build a 3D printed car from scratch. Project status is currently dormant as I haven\u0026rsquo;t had time to iterate over the design due to the complexity and required time investment. The project was gradually being built over the course of 2020 and 2021. Though incomplete, I may return to this project at a later stage (with a smaller scope) after finishing some other projects. The project requires some simplification for the desired goal of having a robust car design. I will share the existing highlights of this projects for the time being. Link to Project Document Discussing Changes From V1 to V2 on Google Drive\nLink to programming of control loop for 3D Printed Car\nSolidworks Design Side View Back View Isometric View Programming Processing3 Controller Program - Bluetooth Interface import processing.serial.*; import controlP5.*; Serial myPort; ControlP5 cp5; //Initialising Global Variables int Motor_Speed = 0; int Steering = 0; int Forward = 0; int Backward = 0; String angleStatus; void setup() { //Inserting Controller Buttons and Sliders size(450,500); cp5 = new ControlP5(this); cp5.addSlider(\u0026#34;Steering\u0026#34;).setPosition(50,150). setSize(200, 100). setRange(0,255); cp5.addSlider(\u0026#34;Motor_Speed\u0026#34;).setPosition(50,275). setSize(175, 100). setRange(0,205); cp5.addButton(\u0026#34;Forward\u0026#34;).setValue(205).setPosition(300,150).setSize(100,100); cp5.addButton(\u0026#34;Backward\u0026#34;).setValue(205).setPosition(300,275).setSize(100,100); //Initialising Bluetooth Communication myPort = new Serial(this, \u0026#34;COM3\u0026#34;, 9600); // Starts the serial communication at 9600 baud rate myPort.bufferUntil(\u0026#39;\\n\u0026#39;);// Reading Serial Data up to new line. The character \u0026#39;\\n\u0026#39; or \u0026#39;New Line\u0026#39; } void serialEvent (Serial myPort){// Checks for available data in the Serial Port angleStatus = myPort.readStringUntil(\u0026#39;\\n\u0026#39;);//Reads the data sent from the Arduino } void draw (){ //Drawing Title and Backround of Controller background(20,150,200); fill(120,170,220); rect(10,10,425,50); fill(0); textSize(23); text(\u0026#34;RC Car Bluetooth Controller Interface\u0026#34;,15,45); //Defining RC Car Parameters 000-000-0 //000-xxx-x = Steering //xxx-000-x = Motor Speed //xxx-xxx-0 = Motor ON/OFF //String needs to be defined inside the draw function to keep updating strings String sfSteering = nf(Steering,3); //3-digit steering value String sfMotor_Speed = nf(Motor_Speed,3); //3-digit motor-speed value if(mousePressed\u0026amp;\u0026amp; mouseX\u0026gt;300 \u0026amp;\u0026amp; mouseX\u0026lt;400 \u0026amp;\u0026amp; mouseY\u0026gt;150 \u0026amp;\u0026amp; mouseY\u0026lt;250){ println(\u0026#39;\u0026lt;\u0026#39;+sfSteering + sfMotor_Speed + \u0026#34;1\u0026#34;+\u0026#39;\u0026gt;\u0026#39;); myPort.write(\u0026#39;\u0026lt;\u0026#39;+sfSteering + sfMotor_Speed + \u0026#34;1\u0026#34;+\u0026#39;\u0026gt;\u0026#39;); delay(100);} //Send Go FWD String to Arduino else if(mousePressed\u0026amp;\u0026amp; mouseX\u0026gt;300 \u0026amp;\u0026amp; mouseX\u0026lt;400 \u0026amp;\u0026amp; mouseY\u0026gt;275 \u0026amp;\u0026amp; mouseY\u0026lt;375){ println(\u0026#39;\u0026lt;\u0026#39;+sfSteering + sfMotor_Speed + \u0026#34;2\u0026#34;+\u0026#39;\u0026gt;\u0026#39;); myPort.write(\u0026#39;\u0026lt;\u0026#39;+sfSteering + sfMotor_Speed + \u0026#34;2\u0026#34;+\u0026#39;\u0026gt;\u0026#39;); delay(100);} //Send Go BCK String to Arduino else{ println(\u0026#39;\u0026lt;\u0026#39;+sfSteering + sfMotor_Speed + \u0026#34;0\u0026#34;+\u0026#39;\u0026gt;\u0026#39;); myPort.write(\u0026#39;\u0026lt;\u0026#39;+sfSteering + sfMotor_Speed + \u0026#34;0\u0026#34;+\u0026#39;\u0026gt;\u0026#39;); delay(100);} //Send STOP String to Arduino } Arduino Control Loop #include \u0026lt;Servo.h\u0026gt; //for reading characters in const byte numChars = 32; char receivedChars[numChars]; boolean newData = false; //Inititalise Servo Servo myServo; //Define Motor H-Bridge Parameters int In1 = 7; int In2 = 8; int ENA = 5; //Define variables for incoming bluetooth data long tmr; int flag = 0; String RCSteer; String RCMotorSpeed; String Motor_Polarity; int RCSteer_Int ; int RCMotorSpeed_Int; int Motor_Polarity_Int; int angle; char c; void setup() { //Inialise Servo Data Pin myServo.attach(3); //Initialise H-Bridge Pins Data Output pinMode (In1, OUTPUT); pinMode (In2, OUTPUT); pinMode (ENA, OUTPUT); //Initialise Bluetooth Serial communication + Serial Interupt Signal Serial.begin(9600); delay(100); } void loop() { //Read Strings into Arduino recvWithStartEndMarkers(); showNewData(); //Convert Character Array to String Object String RCString = receivedChars; //Extract Control Components RCSteer = RCString.substring(0, 3); RCMotorSpeed = RCString.substring(3, 6); Motor_Polarity = RCString.substring(6, 7); //Convert Strings to Integers RCSteer_Int = RCSteer.toInt(); RCMotorSpeed_Int = RCMotorSpeed.toInt(); Motor_Polarity_Int = Motor_Polarity.toInt(); //Print data to Serial Monitor Serial.print(\u0026#34;RCcode: \u0026#34;); Serial.print(receivedChars); Serial.print(\u0026#34; Steering Value: \u0026#34;); Serial.print(RCSteer_Int); Serial.print(\u0026#34; ANGLE: \u0026#34;); Serial.print(angle); Serial.print(\u0026#34; Speed Value: \u0026#34;); Serial.print(RCMotorSpeed_Int); Serial.print(\u0026#34; Polarity Value: \u0026#34;); Serial.println(Motor_Polarity_Int); //Calling Steer and MotorControl Functions Steer(RCSteer_Int); MotorControl(Motor_Polarity_Int,RCMotorSpeed_Int); } void Steer(int RCSteer_Int){ //Send Steering Data to Servo angle = map(RCSteer_Int, 0, 255, 0, 180); myServo.write(angle); } void MotorControl(int Motor_Polarity_Int, int RCMotorSpeed_Int){ //Motor Logic switch(Motor_Polarity_Int){ // FORWARDS case 1: analogWrite(ENA, RCMotorSpeed_Int); digitalWrite(In1, HIGH); digitalWrite(In2, LOW); break; // BACKWARDS case 2: analogWrite(ENA, RCMotorSpeed_Int); digitalWrite(In1, LOW); digitalWrite(In2, HIGH); break; // STOP case 0: digitalWrite(In1, LOW); digitalWrite(In2, LOW); break; } } void recvWithStartEndMarkers() { static boolean recvInProgress = false; static byte ndx = 0; char startMarker = \u0026#39;\u0026lt;\u0026#39;; char endMarker = \u0026#39;\u0026gt;\u0026#39;; char rc; while (Serial.available() \u0026gt; 0 \u0026amp;\u0026amp; newData == false) { rc = Serial.read(); if (recvInProgress == true) { if (rc != endMarker) { receivedChars[ndx] = rc; ndx++; if (ndx \u0026gt;= numChars) { ndx = numChars - 1; } } else { receivedChars[ndx] = \u0026#39;\\0\u0026#39;; // terminate the string recvInProgress = false; ndx = 0; newData = true; } } else if (rc == startMarker) { recvInProgress = true; } } } void showNewData() { if (newData == true ){ newData = false; } } ","permalink":"https://filpill.github.io/eng_projects/3dcar/","tags":["design","engineering","mechanical","automotive","bluetooth","processing3","3d-printing","programming","mechatronics"],"title":"3D Printed Car - Bluetooth Controller Interface"},{"categories":["engineering"],"contents":"Summary Re-writing 2D heat transfer simulation designed in MATLAB to Python. Solved using Successive Over Relaxation Algorithm and Finite Difference Method used to capture incremental changes of temeperature on grid. Animated the heat transitions in Python at each timestep using FuncAnimation component of matplotlib. LHS boundaries on the mesh and the application of the heat input on the leftmost nodes. Heat Input lasts 2 seconds in resulting simulation before being turned off. Link to Heat Transfer Project\n","permalink":"https://filpill.github.io/eng_projects/ht_sim/","tags":["python","matlab","thermodynamics","simulation","programming"],"title":"2D Heat Transfer Simulation"},{"categories":["engineering","design"],"contents":"Summary My elected project for my 4th year in University was to design and build a UAV aircraft. The design requirements were driven out from the 2017 BMFA competition (Payload Challenge). The design had to be capable of flying some circuits with varying volumes of water weighing up to 3.5kg. As project engineer, I was responsible for coordinating the technical requirements and outputs between our sub-teams. Link to Project Report For UAV Design Process\nAircraft Design Process The aircraft design process used in this project is an adaptation of the design process learnt in university for commercial passenger aircraft design. The design tools and flight mechanic equations developed previously have been repurposed such to fit the requirements for a UAV application.\nTo narrow the focus of our design point, data is collected on other aircraft configurations focused around payload missions. This data collection and market analysis process is a critical element to estimating the conceptual aircraft size and Maximum Take-off Weight (MTOW).\nThe design feasibility relies on estimating a relatively sensible MTOW. It is expected that early MTOW estimates may vary ±20% from the final result, however it is sufficient as a starting point.\nThe entire design process is cyclic and interdependant on other design elements, for example: adjustments in aerodynamic configuration may require a re-assessment of the centre of gravity positioning. There are hundreds of other situtations were systems are interconnected and require engineering attention.\nBeyond the conceptual design, we are relying on emulating design practices within the aircraft model building community in order to achieve a mechnical design that does not add any unecessary weight.\nWe have elected to stick with a highly conventional configuration which has been tried and tested. The materials involved are mixture between balsawood, plywood and carbon fibre. This list of materials provide a good stength to weight ratio for the mission we are designing for.\nAreas of the aircaft which experience high loading (e.g. landing gear, wing root etc.) have been reinforced with plywood and less stressed areas are built with the less dense materials such as balsa to maintain a low overall empty weight.\nConceptual Design Phase Detailed Design Phase Aircraft Market Analysis Aircraft CAD Concept Design Derive Flight Equations Preliminary CAD Design Select Appropriate Design Point Solidworks Final CAD Estimate MTOW and OWE Early Prototyping and Testing Decide on Aircraft Configuration Design Revisions and Improvement Aircraft Centre of Gravity Estimation Final Manufacturing Output Aerofoil Comparision and Selection Electronic Systems Integration Flight Dynamics Analysis Systems Validation and Testing Material Selection Wind Tunnel Testing Preliminary Structural Analysis Flight Test Solidworks Design Exploded View Standard water bottle storing main payload in fuselage. Supplemented with custom polypropylene wing tanks. Drawing of UAV Assembly (Final Iteration) Conventional aircraft structure with carbon fiber boom connecting tailplane to the fuselage. Manufacturing Early Construction of Aircraft Constructed with sheets of lasercut balsa and plywood jigsawed together into an assembly. Finalised Construction of Aircraft This is the final assembly of the aircraft after gluing/ironing on the skin. Testing Structural Validation Test - Wing Loading Emulated elliptical wind loading distribution on test spar element Spar failure at 8kg of wing loading. Simulating Maximum Wing Loading on Spar Flight Control Testing Installing servos for ailerons and flaps; testing the control mechanisms. Flight test to validate aircraft design and measure flight performance. Flaps and Ailerons Flight Test Pitch Control ","permalink":"https://filpill.github.io/eng_projects/uav/","tags":["design","engineering","uav","aircraft","aerodynamics","flight-dynamics","electronics","propulsion","solidworks","MATLAB"],"title":"UAV Aircraft Design"},{"categories":["engineering","design"],"contents":"Summary My 3rd year project in University was to design a Forward Facing Step and perform wind tunnel experiments to analyse flow characteristics on that geometry using PIV.\nParticle Image Velocimetry is a practical tool for Aerodynamics analyse flow fields without intrusions in the wind tunnel environment such as sensors or pitot probes.\nIn this experiment the height of the boundary layer is similarly proportioned to the height of the step. In results shown below you will notice two distinct separation regions on the aerofoil. One at the bottom of the step due to the sudden adverse pressure gradient. And another at the top of the step as the flow is unable to sharply turn the corner.\nLink to dissertation\nLink to PIV Python Code For Results Post Processing\nExperimental Procedure Wind Tunnel Experiment The experimental procedure involves diffusing small oil droplets into the freestream flow and having a sheet of laser light illuminating a cross-section of the airflow. Hundreds of images are caputured in the process a high speed camera. Due to the limited field of vision, the results from the top and bottom of the step were recorded seperately. Image Post-Processing Images need some further preparation to enable reliable PIV results. Usually this involves enhancing contrast of the images to make the particles visible. Additionally any background noise picked up by the camera needs to be subtracted from the image as we want to isolate the airflow as much as possible. OpenPIV and Python Post-Process Scripts Particle displacements on the images can be determined by performing a cross-corrleation on the series of image pairs. In my case, I used OpenPIV software written in Python to extract all the velocity fields at all the times steps recorded. Additionally, I\u0026rsquo;ve written some post-processing scripts for the velocity data text files in Python to animate experimental results. (I used MATLAB equivalents for my dissertation at the time of the project). Experimental Arangement Illustration of camera and laser positioning to capture wind tunnel data. Raw wind tunnel image with imageJ enhancements - Capturing illuminated particles moving over step within laser plane. Particle Image Velocimetry Results Instantaneous Velocity Streamplot Front Step Top Step Time Averaged Velocity Contours Front Step Top Step Turbulence Intensity Contours Front Step Top Step ","permalink":"https://filpill.github.io/eng_projects/piv/","tags":["design","engineering","laser","camera","imageJ","matlab","python","wind tunnel","aerodynamics"],"title":"Forward Facing Step - Particle Image Velocimetry"},{"categories":null,"contents":"","permalink":"https://filpill.github.io/search/","tags":null,"title":"Search"}]