<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>webscraping on Filip Livancic</title>
    <link>https://filpill.github.io/tags/webscraping/</link>
    <description>Recent content in webscraping on Filip Livancic</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 03 Oct 2023 00:00:00 +0000</lastBuildDate><atom:link href="https://filpill.github.io/tags/webscraping/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Python Web Scraping</title>
      <link>https://filpill.github.io/data_projects/scrape/</link>
      <pubDate>Tue, 03 Oct 2023 00:00:00 +0000</pubDate>
      
      <guid>https://filpill.github.io/data_projects/scrape/</guid>
      <description>Summary Extracting data from public facing websites is a challenging, yet rewarding prospect.
The data contained inside each website holds information that could help leverage better decision making: e.g. comparing various products and services with various metrics such as price and ratings.
Modern website designs are increasingly making it more challenging to extract data due to:
The stress put on the server with rate of requests being made. Cutting into their profit margins by using the collected data against them.</description>
    </item>
    
    <item>
      <title>Chess.com API - Data Visualisation</title>
      <link>https://filpill.github.io/data_projects/chess/</link>
      <pubDate>Mon, 10 Apr 2023 00:00:00 +0000</pubDate>
      
      <guid>https://filpill.github.io/data_projects/chess/</guid>
      <description>Summary I&amp;rsquo;ve played a decent number of chess games on the chess.com platform since 2019 and all my chess data can be explored using the API endpoints documented inside the website.
I was interested in monitoring my rating change over the cumalative number of games played.
Link to the project here: Chess.com - Python Analysis
Analytics Process Flow graph TD; subgraph Process Initiation 0([Python Notebook Executed])--&gt;A[HTTPS Request Chess Username Stats] end subgraph Data Extraction A--&gt;B[Requesting List of Month Endpoints] B--&gt;C[Request List Games For Each Month Endpoint] C--&gt;D[Unpack all Games into Dataframe] end subgraph Data Cleaning D--&gt;E[Filtering to Blitz Chess Games] E--&gt;F[Cleaning pgn Chess data</description>
    </item>
    
    <item>
      <title>Valorant API - Web Scraping Project</title>
      <link>https://filpill.github.io/page_archive/val_scrp/</link>
      <pubDate>Mon, 13 Jun 2022 00:00:00 +0000</pubDate>
      
      <guid>https://filpill.github.io/page_archive/val_scrp/</guid>
      <description>Summary I was searching for a Valorant API to collect and analyse some of my own match data. However the developers are not providing personal API keys for this particular game.
There are some websites which are publishing the Valorant data into the public domain. I decided to scrape my own match data which is being hosted on their web clients.
Though the volume of data highlighted on the website is limited compared to the actual volume of games I&amp;rsquo;ve played.</description>
    </item>
    
  </channel>
</rss>
